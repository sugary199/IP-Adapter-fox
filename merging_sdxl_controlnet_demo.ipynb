{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, StableDiffusionXLPipeline\n",
    "from PIL import Image\n",
    "\n",
    "from ip_adapter import IPAdapterXL\n",
    "from numpy.random import randint\n",
    "\n",
    "base_model_path = \"/ML-A100/team/mm/wangtao/share/models/stable-diffusion-xl-base-1.0\"\n",
    "image_encoder_path = \"models/image_encoder\"\n",
    "ip_ckpt = \"sdxl_models/ip-adapter_sdxl_vit-h.bin\"\n",
    "device = \"cuda\"\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "# load SDXL pipeline\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    add_watermarker=False,\n",
    ")\n",
    "\n",
    "# load ip-adapter\n",
    "ip_model = IPAdapterXL(pipe, image_encoder_path, ip_ckpt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image prompt\n",
    "image = Image.open(\"/ML-A100/team/mm/shuyu/examples/woman.jpg\")\n",
    "if image.mode=='RGBA':\n",
    "    image=image.convert('RGB')\n",
    "    \n",
    "image.resize((512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image variations\n",
    "num_samples = 3\n",
    "images = ip_model.generate(pil_image=image, num_samples=num_samples, num_inference_steps=30, seed=4)\n",
    "grid = image_grid(images, 1, num_samples)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multimodal prompts\n",
    "# from numpy.random import randint\n",
    "num_samples = 3\n",
    "random_seed = randint(0, 2**32 - 1)\n",
    "images = ip_model.generate(pil_image=image, num_samples=num_samples, num_inference_steps=30, seed=random_seed,\n",
    "        prompt=\"A girl stands on the top of a mountain with her back to the camera. Surrounded by rolling mountains and misty clouds. The figure's back looks firm and lonely\", scale=0.6)\n",
    "grid = image_grid(images, 1, num_samples)\n",
    "# display(grid.resize((900,510)))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ControlNet Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "del pipe, ip_model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "controlnet_path = \"/ML-A100/team/mm/wangtao/share/models/controlnet/controlnet-depth-sdxl-1.0\"\n",
    "# load SDXL pipeline\n",
    "controlnet = ControlNetModel.from_pretrained(controlnet_path, variant=\"fp16\", use_safetensors=True, torch_dtype=torch.float16).to(device)\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    controlnet=controlnet,\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    add_watermarker=False,\n",
    ").to(device)\n",
    "# load ip-adapter\n",
    "ip_model = IPAdapterXL(pipe, image_encoder_path, ip_ckpt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image prompt\n",
    "image = Image.open(\"assets/images/statue.png\")\n",
    "depth_map = Image.open(\"assets/structure_controls/depth.png\").resize((1024, 1024))\n",
    "image_grid([image.resize((256, 256)), depth_map.resize((256, 256))], 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image with structural control\n",
    "num_samples = 3\n",
    "images = ip_model.generate(pil_image=image, image=depth_map, controlnet_conditioning_scale=0.7, num_samples=num_samples, num_inference_steps=30, seed=42)\n",
    "grid = image_grid(images, 1, num_samples)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
